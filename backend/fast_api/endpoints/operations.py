from fastapi import APIRouter, Depends, HTTPException, status, Header
from sqlalchemy.orm import Session
from typing import Optional

import logging
from datetime import datetime, timedelta

# ë©”ì„œë“œ import
from debug import debugging
from db.database import get_db
from db.models import User
from fast_api.security import get_current_user
from llm import invoke
from fast_api.endpoints import op_schemas
from services.operation_store import get_operation_store, OperationStore

import uuid
import re


router = APIRouter()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


@router.post("/stage", response_model=op_schemas.StageOperationResponse)
async def stage_operation(
    request: op_schemas.StageOperationRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    operation_store: OperationStore = Depends(get_operation_store),
    accept_language: Optional[str] = Header(default=None, alias="Accept-Language")
):
    """
    ìì—°ì–´ ëª…ë ¹ì„ ë¶„ì„í•˜ê³  ì‘ì—…ì„ ì¤€ë¹„í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        request: ì‚¬ìš©ì ëª…ë ¹ê³¼ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        current_user: í˜„ì¬ ì¸ì¦ëœ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        operation_store: Redis ì‘ì—… ì €ì¥ì†Œ
        accept_language: Accept-Language header

    
    Returns:
        OperationResponse: ì¤€ë¹„ëœ ì‘ì—… ì •ë³´
    """
    try:
        logger.info(f"Stage operation request from user {current_user.id}: {request.command}")
        # Extract language from Accept-Language header (default to 'ko')
        language = accept_language.split(',')[0].strip().lower() if accept_language else 'ko'
        logger.debug(f"ğŸˆ¯ Detected language from header: {language}")

        # TODO: Pass `language` to downstream logic (LLM prompt, i18n, etc.) as needed.

        # command ê°’ ì ‘ê·¼
        command = request.command

        # context ê°’ ì ‘ê·¼
        context = request.context

        # contextì˜ í•˜ìœ„ ì•„ì´í…œ ì ‘ê·¼
        current_path = context.currentPath
        selected_files = context.selectedFiles
        available_folders = context.availableFolders
        timestamp = context.timestamp

        # íƒ€ì…ì„ ê²°ì •.
        operation_type = invoke.get_operation_type(command)

        # íƒ€ì… ë³„ AI í˜¸ì¶œ ë¶„ê¸°. ê° í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ë¡œ command, contextì „ë‹¬.
        if operation_type == "move":
            result = await process_move(command, context)
        elif operation_type == "copy":
            result = await process_copy(command, context)
        elif operation_type == "delete":
            result = process_delete(command, context)
        elif operation_type == "rename":
            result = process_rename(command, context)
        elif operation_type == "create_folder":
            result = process_create_folder(command, context)
        elif operation_type == "search":
            result = process_search(command)
        elif operation_type == "summarize":
            result = process_summarize(command, context)
        elif operation_type == "error":
            result = process_error(command, operation_type)

        # âœ… Redisì— ì‘ì—… ì •ë³´ ì €ì¥ (error íƒ€ì… ì œì™¸)
        if operation_type != "error":
            # Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° êµ¬ì¡° ê²€ì¦
            operation_store_data = op_schemas.OperationStoreData(
                operation_id=result.operationId,
                command=command,
                context={
                    "currentPath": current_path,
                    "selectedFiles": [dict(file) for file in selected_files],
                    "availableFolders": [dict(folder) for folder in available_folders],
                    "timestamp": timestamp.isoformat() if timestamp else datetime.now().isoformat()
                },
                operation=dict(result.operation),
                requiresConfirmation=result.requiresConfirmation,
                riskLevel=result.riskLevel,
                preview=dict(result.preview),
                user_id=current_user.id,
                created_at=datetime.now().isoformat()
            )
            
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ Redisì— ì €ì¥
            operation_data = operation_store_data.dict()
            
            # Redisì— ì €ì¥
            if not operation_store.store_operation(result.operationId, operation_data):
                logger.error(f"Failed to store operation {result.operationId} in Redis")
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail="ì‘ì—… ì •ë³´ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
                )
            
            logger.info(f"Operation {result.operationId} stored successfully in Redis")

        # ê²°ê³¼ ë°˜í™˜
        return result
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"Unexpected error in stage_operation: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì‘ì—… ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        )

@router.post("/{operation_id}/execute", response_model=op_schemas.ExecutionResponse)
async def execute_operation(
    operation_id: str,
    request: op_schemas.ExecuteOperationRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    operation_store: OperationStore = Depends(get_operation_store)
):
    """
    ì¤€ë¹„ëœ ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        operation_id: ì‹¤í–‰í•  ì‘ì—…ì˜ ID
        request: ì‚¬ìš©ì í™•ì¸ ë° ì˜µì…˜
        current_user: í˜„ì¬ ì¸ì¦ëœ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        operation_store: Redis ì‘ì—… ì €ì¥ì†Œ
    
    Returns:
        ExecutionResponse: ì‹¤í–‰ ê²°ê³¼ ì •ë³´
    """
    logger.info(f"Execute operation {operation_id} for user {current_user.id}")
    # debugging.stop_debugger()
    
    try:
        # Redisì—ì„œ ì‘ì—… ì •ë³´ ì¡°íšŒ
        operation_data = operation_store.get_operation(operation_id)
        
        if not operation_data:
            logger.warning(f"Operation not found: {operation_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
            )
        
        # ì‚¬ìš©ì ê¶Œí•œ í™•ì¸
        if operation_data.get("user_id") != current_user.id:
            logger.warning(f"Unauthorized access attempt for operation {operation_id} by user {current_user.id}")
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ì´ ì‘ì—…ì— ëŒ€í•œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # ì‘ì—… íƒ€ì… í™•ì¸
        operation = operation_data.get("operation", {})
        operation_type = operation.get("type")
        
        logger.info(f"Executing {operation_type} operation: {operation_id}")
        
        # ì‘ì—… íƒ€ì…ë³„ ì‹¤ì œ ì‹¤í–‰ ë¡œì§
        execution_result = await execute_operation_logic(operation_type, operation, request.userOptions, current_user, db)
        
        # ~~ì‹¤í–‰ ì™„ë£Œ í›„ Redisì—ì„œ ì‘ì—… ì •ë³´ ì‚­ì œ~~ ì‹¤í–‰ í›„ ì‚­ì œí•˜ë©´ ì•ˆ ë¨.
        # operation_store.delete_operation(operation_id)
        
        # ì„±ê³µ ì‘ë‹µ ìƒì„±
        response = op_schemas.ExecutionResponse(
            message=execution_result.get("message", "ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"),
            undoAvailable=execution_result.get("undoAvailable", False),
            undoDeadline=execution_result.get("undoDeadline"),
            results=execution_result.get("results"),
            searchResults=execution_result.get("searchResults"),
            summaries=execution_result.get("summaries")
        )
        
        logger.info(f"Operation {operation_id} executed successfully")
        # ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸
        # debugging.redis_store_test(operation_id)

        return response
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"Unexpected error executing operation {operation_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        )

@router.post("/{operation_id}/cancel", response_model=op_schemas.BasicResponse)
async def cancel_operation(
    operation_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    operation_store: OperationStore = Depends(get_operation_store)
):
    """
    ì¤€ë¹„ëœ ì‘ì—…ì„ ì·¨ì†Œí•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        operation_id: ì·¨ì†Œí•  ì‘ì—…ì˜ ID
        current_user: í˜„ì¬ ì¸ì¦ëœ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        operation_store: Redis ì‘ì—… ì €ì¥ì†Œ
    
    Returns:
        BasicResponse: ì·¨ì†Œ ê²°ê³¼ ë©”ì‹œì§€
    """
    logger.info(f"Cancel operation {operation_id} for user {current_user.id}")
    
    try:
        # Redisì—ì„œ ì‘ì—… ì •ë³´ ì¡°íšŒ
        operation_data = operation_store.get_operation(operation_id)
        
        if not operation_data:
            logger.warning(f"Operation not found for cancellation: {operation_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ì·¨ì†Œí•  ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì´ë¯¸ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
            )
        
        # ì‚¬ìš©ì ê¶Œí•œ í™•ì¸
        if operation_data.get("user_id") != current_user.id:
            logger.warning(f"Unauthorized cancel attempt for operation {operation_id} by user {current_user.id}")
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ì´ ì‘ì—…ì„ ì·¨ì†Œí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # Redisì—ì„œ ì‘ì—… ì •ë³´ ì‚­ì œ
        if operation_store.delete_operation(operation_id):
            logger.info(f"Operation {operation_id} cancelled successfully")
            return op_schemas.BasicResponse(message="ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
        else:
            logger.warning(f"Failed to delete operation {operation_id} from Redis")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ì‘ì—… ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
            )
            
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"Unexpected error cancelling operation {operation_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì‘ì—… ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        )

@router.post("/{operation_id}/undo", response_model=op_schemas.BasicResponse)
async def undo_operation(
    operation_id: str,
    request: op_schemas.UndoOperationRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    operation_store: OperationStore = Depends(get_operation_store)
):
    """
    ì‹¤í–‰ëœ ì‘ì—…ì„ ë˜ëŒë¦¬ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    Args:
        operation_id: ë˜ëŒë¦´ ì‘ì—…ì˜ ID
        request: ë˜ëŒë¦¬ê¸° ì‚¬ìœ  ë° ì‹œê°„
        current_user: í˜„ì¬ ì¸ì¦ëœ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        operation_store: Redis ì‘ì—… ì €ì¥ì†Œ
    
    Returns:
        BasicResponse: ë˜ëŒë¦¬ê¸° ê²°ê³¼ ë©”ì‹œì§€
    """
    logger.info(f"Undo operation {operation_id} for user {current_user.id}, reason: {request.reason}")
    
    try:
        # ì‹¤í–‰ë˜ì—ˆë˜ ì‘ì—… ì •ë³´ ì¡°íšŒ 
        undo_data = operation_store.get_operation(operation_id)
        
        # ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸
        # debugging.redis_store_test(operation_id)
        # debugging.stop_debugger()

        if not undo_data:
            logger.warning(f"Undo data not found for operation: {operation_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="ë˜ëŒë¦´ ìˆ˜ ìˆëŠ” ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë˜ëŒë¦¬ê¸° ê¸°í•œì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
            )
        
        # ì‚¬ìš©ì ê¶Œí•œ í™•ì¸
        if undo_data.get("user_id") != current_user.id:
            logger.warning(f"Unauthorized undo attempt for operation {operation_id} by user {current_user.id}")
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ì´ ì‘ì—…ì„ ë˜ëŒë¦´ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤"
            )
        
        # ì‘ì—… íƒ€ì…ë³„ undo ë¡œì§ ì‹¤í–‰
        operation_type = undo_data.get("operation", {}).get("type")
        undo_result = await execute_undo_logic(operation_type, undo_data, request.reason, current_user, db)
        
        if undo_result.get("success", False):
            # ì‹¤í–‰ë˜ì—ˆë˜ ì‘ì—… ì •ë³´ ì‚­ì œ
            operation_store.delete_operation(operation_id)
            
            logger.info(f"Operation {operation_id} undone successfully")
            return op_schemas.BasicResponse(
                message=undo_result.get("message", "ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ë˜ëŒë ¤ì¡ŒìŠµë‹ˆë‹¤")
            )
        else:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=undo_result.get("error", "ì‘ì—… ë˜ëŒë¦¬ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            )
            
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"Unexpected error undoing operation {operation_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì‘ì—… ë˜ëŒë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        )


# operation_typeë³„ function ë§Œë“¤ê¸°

async def process_move(command, context):
    """
    ì´ë™ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """
    # ëª…ë ¹ ë¶„ì„
    destination = get_destination(command, context, 'move')
    # ì‘ì—… ì„¤ëª… ìš”ì•½ ìƒì„±.
    description = get_description(context, destination, 'move')

    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    
    # destination íŒŒì‹±. ë§Œì•½ '/'ë¡œ íŒŒì‹± ì‹œ 'create_folder'ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°,
    # destinationì—ì„œ 'create_folder' ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì œê±°
    if destination.startswith('create_folder'):
        code_remove_ver = destination.replace('create_folder', '', 1)

        # destinationì— ì½”ë“œë¥¼ ì œê±°í•œ ê²½ë¡œ ë°ì´í„° ì €ì¥.
        destination = code_remove_ver

        additional_desc = code_remove_ver + " í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
        # ì¶”ê°€ ì„¤ëª… ë¬¸ì¥ ì¶”ê°€.
        description += " "+ additional_desc
    else:
        destination = destination
        description = description
    
    warnings = [] 
    
    # Pydantic ëª¨ë¸ ì‚¬ìš©
    move_operation = op_schemas.MoveOperation(
        targets=context.selectedFiles,
        destination=destination
    )
    
    preview = op_schemas.OperationPreview(
        description=description,
        warnings=warnings
    )
    
    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=move_operation,
        requiresConfirmation=True,
        riskLevel="medium",
        preview=preview
    )

async def process_copy(command, context):
    """
    ë³µì‚¬ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """
    # ëª…ë ¹ ë¶„ì„
    destination = get_destination(command, context, 'copy')
    # ì‘ì—… ì„¤ëª… ìš”ì•½ ìƒì„±.
    description = get_description(context, destination, 'copy')

    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    
    # destination íŒŒì‹±. ë§Œì•½ '/'ë¡œ íŒŒì‹± ì‹œ 'create_folder'ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°,
    # destinationì—ì„œ 'create_folder' ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì œê±°
    if destination.startswith('create_folder'):
        code_remove_ver = destination.replace('create_folder', '', 1)

        # destinationì— ì½”ë“œë¥¼ ì œê±°í•œ ê²½ë¡œ ë°ì´í„° ì €ì¥.
        destination = code_remove_ver

        additional_desc = code_remove_ver + " í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
        # ì¶”ê°€ ì„¤ëª… ë¬¸ì¥ ì¶”ê°€.
        description += " "+ additional_desc
    else:
        destination = destination
        description = description
    
    warnings = [] 
    
    # Pydantic ëª¨ë¸ ì‚¬ìš©
    copy_operation = op_schemas.CopyOperation(
        targets=context.selectedFiles,
        destination=destination
    )
    
    preview = op_schemas.OperationPreview(
        description=description,
        warnings=warnings
    )
    
    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=copy_operation,
        requiresConfirmation=True,
        riskLevel="low",
        preview=preview
    )

def process_delete(command, context):
    """
    ì‚­ì œ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """
    # ì‘ì—… ì„¤ëª… ìš”ì•½ ìƒì„±.
    description = get_description(context, None, 'delete')

    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    warnings = [] 
    
    # Pydantic ëª¨ë¸ ì‚¬ìš©
    delete_operation = op_schemas.DeleteOperation(
        targets=context.selectedFiles
    )
    
    preview = op_schemas.OperationPreview(
        description=description,
        warnings=warnings
    )
    
    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=delete_operation,
        requiresConfirmation=True,
        riskLevel="high",
        preview=preview
    )

def process_error(command, operation_type):
    """
    ì˜¤ë¥˜ ìƒí™©ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        error_type: ì—ëŸ¬ íƒ€ì… (err-1 ë˜ëŠ” err-2)
        
    Returns:
        ì—ëŸ¬ ì •ë³´ë¥¼ ë‹´ì€ ê²°ê³¼ ê°ì²´
    """
    # ë°ì´í„° ì¤€ë¹„
    operation_id = "error-"+str(uuid.uuid4())
    
    # ì—ëŸ¬ íƒ€ì…ë³„ ë©”ì‹œì§€ ë° ê°€ì´ë“œ ì„¤ì •
    if operation_type == "error":
        # ë¶€ì •í‘œí˜„ ë˜ëŠ” íŒŒì¼ê´€ë ¨ì´ì§€ë§Œ ë§¤ì¹­ì•ˆë¨
        message = "íŒŒì¼ ê´€ë¦¬ì™€ ê´€ë ¨ì—†ëŠ” ëª…ë ¹ì´ê±°ë‚˜, ëª…ë ¹ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
        description = f"ì…ë ¥í•˜ì‹  ëª…ë ¹ '{command}'ì„(ë¥¼) ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        warnings = ["ì ì ˆí•œ ëª…ë ¹ì„ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì‹­ì‹œì˜¤."]
    else:
        # ê¸°ë³¸ ì—ëŸ¬ ë©”ì‹œì§€
        message = "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        description = "ì‹œìŠ¤í…œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        warnings = ["ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."]
    
    # ë¡œê·¸ ê¸°ë¡
    logger.warning(f"Error processing command: '{command}', Error type: error")
    
    # Pydantic ëª¨ë¸ ì‚¬ìš©
    error_operation = op_schemas.ErrorOperation(
        error_type="error",
        message=message
    )
    
    preview = op_schemas.OperationPreview(
        description=description,
        warnings=warnings
    )
    
    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operation_id,
        operation=error_operation,
        requiresConfirmation=False,
        riskLevel="none",
        preview=preview
    )

def process_rename(command, context):
    """
    ì´ë¦„ ë³€ê²½ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """

    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    new_name = get_new_name(command)
    description = generate_rename_description(context, new_name)
    # debugging.stop_debugger()

    # Pydantic ëª¨ë¸ ì‚¬ìš©
    rename_operation = op_schemas.RenameOperation(
        target=context.selectedFiles,
        newName=new_name
    )
    
    preview = op_schemas.OperationPreview(
        description=description
    )

    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=rename_operation,
        requiresConfirmation=True,
        riskLevel="medium",
        preview=preview
    )

def process_create_folder(command, context):
    """
    í´ë” ìƒì„± ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """
    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    folder_name = get_new_folder_name(command)
    parent_Path = get_parent_path(command, context)
    description = generate_create_folder_description(folder_name, parent_Path)

    # parent_Path íŒŒì‹±. ë§Œì•½ 'create_folder'ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°,
    # parent_Pathì—ì„œ 'create_folder' ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì œê±°
    if parent_Path.startswith('create_folder'):
        code_remove_ver = parent_Path.replace('create_folder', '', 1)

        # parent_Pathì— ì½”ë“œë¥¼ ì œê±°í•œ ê²½ë¡œ ë°ì´í„° ì €ì¥.
        parent_Path = code_remove_ver

        additional_desc = folder_name + " í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
        # ì¶”ê°€ ì„¤ëª… ë¬¸ì¥ ì¶”ê°€.
        description += " " + additional_desc

    # Pydantic ëª¨ë¸ ì‚¬ìš©
    create_folder_operation = op_schemas.CreateFolderOperation(
        folderName=folder_name,
        parentPath=parent_Path
    )
    
    preview = op_schemas.OperationPreview(
        description=description
    )

    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=create_folder_operation,
        requiresConfirmation=True,
        riskLevel="low",
        preview=preview
    )

def process_search(command):
    """
    ê²€ìƒ‰ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """
    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    search_term = get_search_term(command)
    description = generate_search_description(search_term)

    # Pydantic ëª¨ë¸ ì‚¬ìš©
    search_operation = op_schemas.SearchOperation(
        searchTerm=search_term
    )
    
    preview = op_schemas.OperationPreview(
        description=description
    )

    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=search_operation,
        requiresConfirmation=False,
        riskLevel="low",
        preview=preview
    )

def process_summarize(command, context):
    """
    ìš”ì•½ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        
    Returns:
        ì‘ì—… ê²°ê³¼ ì •ë³´
    """

    # ë°ì´í„° ì¤€ë¹„
    operationId = "op-"+str(uuid.uuid4())
    description = generate_summarize_description(context)

    # Pydantic ëª¨ë¸ ì‚¬ìš©
    summarize_operation = op_schemas.SummarizeOperation(
        targets=context.selectedFiles
    )
    
    preview = op_schemas.OperationPreview(
        description=description
    )

    # StageOperationResponse ê°ì²´ ìƒì„±
    return op_schemas.StageOperationResponse(
        operationId=operationId,
        operation=summarize_operation,
        requiresConfirmation=True,
        riskLevel="low",
        preview=preview
    )





def get_destination(command, context, operation_type):
    """
    ëª©ì ì§€ ê²½ë¡œë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        operation_type: ì‘ì—… íƒ€ì… ('move' ë˜ëŠ” 'copy')
    
    Returns:
        str: ëª©ì ì§€ ê²½ë¡œ
    """

    # ëª©ì ì§€ ê²½ë¡œ ì¶”ì¶œ
    if operation_type == 'move':
        output_destination = extract_move_destination(command, context)
    elif operation_type == 'copy':
        # copy ë¡œì§ì€ ë‚˜ì¤‘ì— êµ¬í˜„
        output_destination = extract_copy_destination(command, context)
    # ...

    return output_destination

def get_description(context, destination = '/', operation_type = "default", new_name = None):
    """
    
    
    Returns:
        str: output_description
    """
    if operation_type == 'move':
        output_description = generate_move_description(context, destination)
    elif operation_type == 'copy':
        output_description = generate_copy_description(context, destination)
    elif operation_type == 'delete':
        output_description = generate_delete_description(context)
    elif operation_type == 'rename':
        output_description = generate_rename_description(context, new_name)
    else:
        output_description = "ì‘ì—… ì„¤ëª… ë¬¸ì¥ ìƒì„± ì˜¤ë¥˜"

    return output_description

def extract_move_destination(command, context):
    """
    ì´ë™ ì‘ì—…ì— ëŒ€í•œ ëª©ì ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
    """
    # 1. ì‚¬ìš©ì ëª…ë ¹ì—ì„œ ëª©ì ì§€ ì¶”ì¶œ
    input_destination = None
    
    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ëª©ì ì§€ ì¶”ì¶œ ì‹œë„
    patterns = [
        r'(\w+)\s*í´ë”ë¡œ',  # "ë§ˆì¼€íŒ… í´ë”ë¡œ"
        r'(\w+)\s*í´ë”ì—', # "ë§ˆì¼€íŒ… í´ë”ì—"
        r'(\w+)ë¡œ\s*ì´ë™',  # "ë§ˆì¼€íŒ…ë¡œ ì´ë™"
        r'(\w+)ì—\s*ì´ë™',  # "ë§ˆì¼€íŒ…ì— ì´ë™"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ë¡œ', # "ë§ˆì¼€íŒ… ë””ë ‰í† ë¦¬ë¡œ"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ì—', # "ë§ˆì¼€íŒ… ë””ë ‰í† ë¦¬ì—"
        r'ë¡œ\s*ì˜®ê²¨.*?(\w+)', # "ë¡œ ì˜®ê²¨ ë§ˆì¼€íŒ…"
        r'ì—\s*ì˜®ê²¨.*?(\w+)', # "ì— ì˜®ê²¨ ë§ˆì¼€íŒ…"
    ]
    
    # ê° íŒ¨í„´ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ëª©ì ì§€ ì¶”ì¶œ
    for pattern in patterns:
        match = re.search(pattern, command)
        if match:
            input_destination = match.group(1)
            break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì—ì„œ ì¤‘ë‹¨
    
    # 2. availableFoldersì—ì„œ ë§¤ì¹­ë˜ëŠ” path ì°¾ê¸°
    if input_destination:
        for folder in context.availableFolders:
            if folder.get('name') == input_destination:
                output_destination = folder.get('path')
                return output_destination
    
    # ë§¤ì¹­ë˜ëŠ” í´ë”ê°€ ì—†ëŠ” ê²½ìš° output_destinationì— 'create_folder' ì½”ë“œ ì¶”ê°€.
    if context.availableFolders:
        output_destination = 'create_folder'+'/'+input_destination
    else:
        output_destination = '/'
    
    return output_destination

def generate_move_description(context, destination):
    """
    ì´ë™ ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜

    Args:
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (selectedFiles í¬í•¨)
        destination: ëª©ì ì§€ ê²½ë¡œ ('create_folder/í´ë”ëª…' í˜•íƒœì¼ ìˆ˜ ìˆìŒ)
        
    Returns:
        str: "íŒŒì¼ëª…ë“¤ì„ ëª©ì ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤." í˜•íƒœì˜ ì„¤ëª… ë¬¸ì¥
    """
    # 1. selectedFiles ê°’ ì¤€ë¹„
    # selectedFiles ë¦¬ìŠ¤íŠ¸ì˜ ê° ì•„ì´í…œ ê°ì²´ì˜ nameí‚¤ì˜ ê°’ì„ ë‚˜ì—´í•˜ì—¬ ì €ì¥
    file_names = []
    for file in context.selectedFiles:
        file_names.append(file.get('name', ''))
    st_result = ', '.join(file_names)

    # 2. destination ê°’ íŒŒì‹±
    # destinationì—ì„œ 'create_folder' ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì œê±°
    if destination.startswith('create_folder'):
        ds_result = destination.replace('create_folder', '', 1)
    else:
        ds_result = destination
    
    # 3. description ë¬¸ì¥ ìƒì„±
    desc_result = st_result + "ë¥¼ " + ds_result + "ë¡œ ì´ë™í•©ë‹ˆë‹¤."

    return desc_result

def extract_copy_destination(command, context):
    """
    ë³µì‚¬ ì‘ì—…ì— ëŒ€í•œ ëª©ì ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    
    Returns:
        str: ëª©ì ì§€ ê²½ë¡œ
    """
    # 1. ì‚¬ìš©ì ëª…ë ¹ì—ì„œ ëª©ì ì§€ ì¶”ì¶œ
    input_destination = None
    
    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ëª©ì ì§€ ì¶”ì¶œ ì‹œë„ (ë³µì‚¬ ì‘ì—…ì— ë§ëŠ” íŒ¨í„´ í¬í•¨)
    patterns = [
        r'(\w+)\s*í´ë”ë¡œ',  # "ë§ˆì¼€íŒ… í´ë”ë¡œ"
        r'(\w+)\s*í´ë”ì—', # "ë§ˆì¼€íŒ… í´ë”ì—"
        r'(\w+)ë¡œ\s*ë³µì‚¬',  # "ë§ˆì¼€íŒ…ë¡œ ë³µì‚¬"
        r'(\w+)ì—\s*ë³µì‚¬',  # "ë§ˆì¼€íŒ…ì— ë³µì‚¬"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ë¡œ', # "ë§ˆì¼€íŒ… ë””ë ‰í† ë¦¬ë¡œ"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ì—', # "ë§ˆì¼€íŒ… ë””ë ‰í† ë¦¬ì—"
        r'ë¡œ\s*ë°±ì—….*?(\w+)', # "ë¡œ ë°±ì—… ë§ˆì¼€íŒ…"
        r'ì—\s*ë°±ì—….*?(\w+)', # "ì— ë°±ì—… ë§ˆì¼€íŒ…"
        r'(\w+)\s*í´ë”ì—\s*ë°±ì—…', # "ë§ˆì¼€íŒ… í´ë”ì— ë°±ì—…"
        r'(\w+)\s*í´ë”ë¡œ\s*ë°±ì—…', # "ë§ˆì¼€íŒ… í´ë”ë¡œ ë°±ì—…"
    ]
    
    # ê° íŒ¨í„´ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ëª©ì ì§€ ì¶”ì¶œ
    for pattern in patterns:
        match = re.search(pattern, command)
        if match:
            input_destination = match.group(1)
            break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì—ì„œ ì¤‘ë‹¨
    
    # 2. availableFoldersì—ì„œ ë§¤ì¹­ë˜ëŠ” path ì°¾ê¸°
    if input_destination:
        for folder in context.availableFolders:
            if folder.get('name') == input_destination:
                output_destination = folder.get('path')
                return output_destination
    
    # ë§¤ì¹­ë˜ëŠ” í´ë”ê°€ ì—†ëŠ” ê²½ìš° output_destinationì— 'create_folder' ì½”ë“œ ì¶”ê°€.
    if context.availableFolders:
        output_destination = 'create_folder'+'/'+input_destination
    else:
        output_destination = '/'
    
    return output_destination

def generate_copy_description(context, destination='/'):
    """
    ë³µì‚¬ ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜

    Args:
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (selectedFiles í¬í•¨)
        destination: ëª©ì ì§€ ê²½ë¡œ ('create_folder/í´ë”ëª…' í˜•íƒœì¼ ìˆ˜ ìˆìŒ)
        
    Returns:
        str: "íŒŒì¼ëª…ë“¤ì„ ëª©ì ì§€ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤." í˜•íƒœì˜ ì„¤ëª… ë¬¸ì¥
    """
    # 1. selectedFiles ê°’ ì¤€ë¹„
    # selectedFiles ë¦¬ìŠ¤íŠ¸ì˜ ê° ì•„ì´í…œ ê°ì²´ì˜ nameí‚¤ì˜ ê°’ì„ ë‚˜ì—´í•˜ì—¬ ì €ì¥
    file_names = []
    for file in context.selectedFiles:
        file_names.append(file.get('name', ''))
    st_result = ', '.join(file_names)

    # 2. destination ê°’ íŒŒì‹±
    # destinationì—ì„œ 'create_folder' ë¬¸ìì—´ì´ ìˆìœ¼ë©´ ì œê±°
    if destination.startswith('create_folder'):
        ds_result = destination.replace('create_folder', '', 1)
    else:
        ds_result = destination
    
    # 3. description ë¬¸ì¥ ìƒì„± (ë³µì‚¬ ì‘ì—…ì— ë§ê²Œ ìˆ˜ì •)
    desc_result = st_result + "ë¥¼ " + ds_result + "ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤."

    return desc_result

def generate_delete_description(context):
    """
    ì‚­ì œ ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (selectedFiles í¬í•¨)
        
    Returns:
        str: "ì„ íƒí•œ Xê°œ í•­ëª© (íŒŒì¼Y, í´ë” Z) ì„ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œí•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." í˜•íƒœì˜ ì„¤ëª… ë¬¸ì¥
    """
    # 1. selectedFilesì—ì„œ íŒŒì¼ê³¼ í´ë” ê°œìˆ˜ ì„¸ê¸°
    file_count = 0
    folder_count = 0
    
    for item in context.selectedFiles:
        item_type = item.get('type', '')
        if item_type == 'folder':
            folder_count += 1
        else:
            file_count += 1
    
    # 2. ì „ì²´ í•­ëª© ê°œìˆ˜ ê³„ì‚°
    total_count = file_count + folder_count
    
    # 3. í•­ëª© íƒ€ì…ë³„ ì„¤ëª… ë¬¸êµ¬ ìƒì„±
    type_description_parts = []
    if file_count > 0:
        type_description_parts.append(f"íŒŒì¼{file_count}")
    if folder_count > 0:
        type_description_parts.append(f"í´ë” {folder_count}")
    
    type_description = ", ".join(type_description_parts)
    
    # 4. ìµœì¢… ì„¤ëª… ë¬¸ì¥ ìƒì„±
    desc_result = f"ì„ íƒí•œ {total_count}ê°œ í•­ëª© ({type_description}) ì„ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œí•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    return desc_result

    
def get_new_name(command):
    """
    ì´ë¦„ ë³€ê²½ ì‘ì—…ì— ëŒ€í•œ ìƒˆë¡œìš´ ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
    
    Returns:
        str: ì¶”ì¶œëœ ìƒˆë¡œìš´ ì´ë¦„ (ì—†ìœ¼ë©´ None)
    """
    # 1. ì‚¬ìš©ì ëª…ë ¹ì—ì„œ ìƒˆ ì´ë¦„ ì¶”ì¶œ
    new_name = None
    
    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ìƒˆ ì´ë¦„ ì¶”ì¶œ ì‹œë„
    patterns = [
        r'(\w+?)ìœ¼ë¡œ\s*ë°”ê¿”',  # "ìƒˆì´ë¦„ìœ¼ë¡œ ë°”ê¿”" â†’ "ìƒˆì´ë¦„"
        r'(\w+?)ìœ¼ë¡œ\s*ë³€ê²½',  # "ìƒˆì´ë¦„ìœ¼ë¡œ ë³€ê²½" â†’ "ìƒˆì´ë¦„" 
        r'(\w+?)ìœ¼ë¡œ\s*ìˆ˜ì •',  # "ìƒˆì´ë¦„ìœ¼ë¡œ ìˆ˜ì •" â†’ "ìƒˆì´ë¦„"
        r'(\w+?)ìœ¼ë¡œ\s*ì´ë¦„ë³€ê²½',  # "ìƒˆì´ë¦„ìœ¼ë¡œ ì´ë¦„ë³€ê²½" â†’ "ìƒˆì´ë¦„"
        r'(\w+?)ìœ¼ë¡œ\s*ë¦¬ë„¤ì„',  # "ìƒˆì´ë¦„ìœ¼ë¡œ ë¦¬ë„¤ì„" â†’ "ìƒˆì´ë¦„"
        r'(\w+?)ìœ¼ë¡œ\s*rename',  # "ìƒˆì´ë¦„ìœ¼ë¡œ rename" â†’ "ìƒˆì´ë¦„"
        r'(\w+)ë¡œ\s*ë°”ê¿”',  # "ìƒˆì´ë¦„ë¡œ ë°”ê¿”"
        r'(\w+)ë¡œ\s*ë³€ê²½',  # "ìƒˆì´ë¦„ë¡œ ë³€ê²½"
        r'(\w+)ë¡œ\s*ìˆ˜ì •',  # "ìƒˆì´ë¦„ë¡œ ìˆ˜ì •"
        r'(\w+)ë¡œ\s*ì´ë¦„ë³€ê²½',  # "ìƒˆì´ë¦„ë¡œ ì´ë¦„ë³€ê²½"
        r'(\w+)ë¡œ\s*ë¦¬ë„¤ì„',  # "ìƒˆì´ë¦„ë¡œ ë¦¬ë„¤ì„"
        r'(\w+)ë¡œ\s*rename',  # "ìƒˆì´ë¦„ë¡œ rename" (ì˜ì–´ í˜¼ìš©)
        r'ì´ë¦„ì„\s*(\w+)ë¡œ',  # "ì´ë¦„ì„ ìƒˆì´ë¦„ë¡œ"
        r'ì´ë¦„ì„\s*(\w+?)ìœ¼ë¡œ',  # "ì´ë¦„ì„ ìƒˆì´ë¦„ìœ¼ë¡œ" â†’ "ìƒˆì´ë¦„"
        r'íŒŒì¼ëª…ì„\s*(\w+)ë¡œ',  # "íŒŒì¼ëª…ì„ ìƒˆì´ë¦„ë¡œ"
        r'íŒŒì¼ëª…ì„\s*(\w+?)ìœ¼ë¡œ',  # "íŒŒì¼ëª…ì„ ìƒˆì´ë¦„ìœ¼ë¡œ" â†’ "ìƒˆì´ë¦„"
    ]
    
    # ê° íŒ¨í„´ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ìƒˆ ì´ë¦„ ì¶”ì¶œ
    for pattern in patterns:
        match = re.search(pattern, command)
        if match:
            new_name = match.group(1)
            break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì—ì„œ ì¤‘ë‹¨
    
    return new_name

def generate_rename_description(context, new_name):
    """
    ì´ë¦„ ë³€ê²½ ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (selectedFiles í¬í•¨)
        new_name: ìƒˆë¡œìš´ ì´ë¦„
        
    Returns:
        str: "ë¬¸ì„œ ì´ë¦„ì„ new_name(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤." ë˜ëŠ” "ë””ë ‰í† ë¦¬ ì´ë¦„ì„ new_name(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤." í˜•íƒœì˜ ì„¤ëª… ë¬¸ì¥
    """
    # 1. selectedFilesì—ì„œ ì²« ë²ˆì§¸ ì•„ì´í…œì˜ íƒ€ì… í™•ì¸
    # (rename ì‘ì—…ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì¼ ì•„ì´í…œì— ëŒ€í•´ ìˆ˜í–‰ë¨)
    if context.selectedFiles and len(context.selectedFiles) > 0:
        selected_item = context.selectedFiles[0]
        item_type = selected_item.get('type', '')
        
        # 2. ì•„ì´í…œ íƒ€ì…ì— ë”°ë¥¸ ì„¤ëª… ë¬¸êµ¬ ìƒì„±
        if item_type == 'folder':
            # í´ë”(ë””ë ‰í† ë¦¬)ì¸ ê²½ìš°
            desc_result = f"ë””ë ‰í† ë¦¬ ì´ë¦„ì„ {new_name}(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤."
        else:
            # íŒŒì¼ì¸ ê²½ìš° (ê¸°ë³¸ê°’)
            desc_result = f"ë¬¸ì„œ ì´ë¦„ì„ {new_name}(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤."
    else:
        # ì„ íƒëœ ì•„ì´í…œì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€
        desc_result = f"ì•„ì´í…œ ì´ë¦„ì„ {new_name}(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤."
    
    return desc_result

def get_new_folder_name(command):
    """
    ìƒˆ í´ë” ì´ë¦„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
    """
    # 1. ì‚¬ìš©ì ëª…ë ¹ì—ì„œ ìƒˆ í´ë” ì´ë¦„ ì¶”ì¶œ
    new_dir_name = None
    
    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ìƒˆ í´ë” ì´ë¦„ ì¶”ì¶œ ì‹œë„
    patterns = [
        # ê¸°ë³¸ ìƒì„± íŒ¨í„´
        r'(\w+)\s*í´ë”ë¥¼\s*ìƒì„±',  # "ì‹ ê·œí”„ë¡œì íŠ¸ í´ë”ë¥¼ ìƒì„±"
        r'(\w+)\s*í´ë”\s*ìƒì„±',   # "ì‹ ê·œí”„ë¡œì íŠ¸ í´ë” ìƒì„±"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ë¥¼\s*ìƒì„±',  # "ì‹ ê·œí”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±"
        r'(\w+)\s*ë””ë ‰í† ë¦¬\s*ìƒì„±',   # "ì‹ ê·œí”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±"
        
        # ë§Œë“¤ê¸° íŒ¨í„´
        r'(\w+)\s*í´ë”ë¥¼\s*ë§Œë“¤',  # "ì‹ ê·œí”„ë¡œì íŠ¸ í´ë”ë¥¼ ë§Œë“¤"
        r'(\w+)\s*í´ë”\s*ë§Œë“¤',   # "ì‹ ê·œí”„ë¡œì íŠ¸ í´ë” ë§Œë“¤"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ë¥¼\s*ë§Œë“¤',  # "ì‹ ê·œí”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤"
        r'(\w+)\s*ë””ë ‰í† ë¦¬\s*ë§Œë“¤',   # "ì‹ ê·œí”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë§Œë“¤"
        r'(\w+)ë¥¼\s*ë§Œë“¤ì–´',  # "ì‹ ê·œí”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì–´"
        r'(\w+)\s*ë§Œë“¤ì–´',   # "ì‹ ê·œí”„ë¡œì íŠ¸ ë§Œë“¤ì–´"
        
        # ì¶”ê°€ íŒ¨í„´
        r'ìƒˆ\s*(\w+)ë¥¼\s*ì¶”ê°€',  # "ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ì¶”ê°€"
        r'ìƒˆ\s*(\w+)\s*ì¶”ê°€',   # "ìƒˆ í”„ë¡œì íŠ¸ ì¶”ê°€"
        r'(\w+)ë¥¼\s*ì¶”ê°€',  # "ì‹ ê·œí”„ë¡œì íŠ¸ë¥¼ ì¶”ê°€"
        r'(\w+)\s*ì¶”ê°€',   # "ì‹ ê·œí”„ë¡œì íŠ¸ ì¶”ê°€"
        r'(\w+)\s*í´ë”ë¥¼\s*ì¶”ê°€',  # "ì‹ ê·œí”„ë¡œì íŠ¸ í´ë”ë¥¼ ì¶”ê°€"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ë¥¼\s*ì¶”ê°€',  # "ì‹ ê·œí”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì¶”ê°€"
        
        # ê¸°ë³¸ ìƒì„± íŒ¨í„´ (ê°„ë‹¨í•œ í˜•íƒœ)
        r'(\w+)ë¥¼\s*ìƒì„±',  # "ì‹ ê·œí”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'(\w+)\s*ìƒì„±',   # "ì‹ ê·œí”„ë¡œì íŠ¸ ìƒì„±"
        r'ìƒˆ\s*(\w+)ë¥¼\s*ìƒì„±',  # "ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'ìƒˆ\s*(\w+)\s*ìƒì„±',   # "ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±"
        
        # 'ë¼ëŠ”/ì´ë¼ëŠ”' íŒ¨í„´
        r'(\w+)ë¼ëŠ”\s*í´ë”ë¥¼\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ë¼ëŠ” í´ë”ë¥¼ ìƒì„±"
        r'(\w+)ë¼ëŠ”\s*í´ë”\s*ìƒì„±',   # "í”„ë¡œì íŠ¸ë¼ëŠ” í´ë” ìƒì„±"
        r'(\w+)ë¼ëŠ”\s*ë””ë ‰í† ë¦¬ë¥¼\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ë¼ëŠ” ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±"
        r'(\w+)ë¼ëŠ”\s*ë””ë ‰í† ë¦¬\s*ìƒì„±',   # "í”„ë¡œì íŠ¸ë¼ëŠ” ë””ë ‰í† ë¦¬ ìƒì„±"
        r'(\w+)ì´ë¼ëŠ”\s*í´ë”ë¥¼\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ì´ë¼ëŠ” í´ë”ë¥¼ ìƒì„±"
        r'(\w+)ì´ë¼ëŠ”\s*í´ë”\s*ìƒì„±',   # "í”„ë¡œì íŠ¸ì´ë¼ëŠ” í´ë” ìƒì„±"
        
        # ìƒˆë¡œìš´/ì‹ ê·œ íŒ¨í„´
        r'ìƒˆë¡œìš´\s*(\w+)ë¥¼\s*ìƒì„±',  # "ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'ìƒˆë¡œìš´\s*(\w+)\s*ìƒì„±',   # "ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ìƒì„±"
        r'ì‹ ê·œ\s*(\w+)ë¥¼\s*ìƒì„±',  # "ì‹ ê·œ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'ì‹ ê·œ\s*(\w+)\s*ìƒì„±',   # "ì‹ ê·œ í”„ë¡œì íŠ¸ ìƒì„±"
        
        # ì˜ì–´ í˜¼ìš© íŒ¨í„´
        r'new\s*(\w+)ë¥¼\s*ìƒì„±',  # "new í”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'new\s*(\w+)\s*ìƒì„±',   # "new í”„ë¡œì íŠ¸ ìƒì„±"
        r'(\w+)\s*create',  # "í”„ë¡œì íŠ¸ create"
        r'create\s*(\w+)',  # "create í”„ë¡œì íŠ¸"
        
        # ìœ„ì¹˜ í‘œí˜„ê³¼ í•¨ê»˜
        r'ì—¬ê¸°ì—\s*(\w+)ë¥¼\s*ìƒì„±',  # "ì—¬ê¸°ì— í”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'ì´ê³³ì—\s*(\w+)ë¥¼\s*ìƒì„±',  # "ì´ê³³ì— í”„ë¡œì íŠ¸ë¥¼ ìƒì„±"
        r'(\w+)ë¥¼\s*ì—¬ê¸°ì—\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ë¥¼ ì—¬ê¸°ì— ìƒì„±"
        
        # ê¸°íƒ€ í‘œí˜„
        r'(\w+)\s*í´ë”ë¥¼\s*êµ¬ì„±',  # "í”„ë¡œì íŠ¸ í´ë”ë¥¼ êµ¬ì„±"
        r'(\w+)\s*ë””ë ‰í† ë¦¬ë¥¼\s*êµ¬ì„±',  # "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ êµ¬ì„±"
        r'(\w+)\s*ì´ë¦„ì˜\s*í´ë”ë¥¼\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ ì´ë¦„ì˜ í´ë”ë¥¼ ìƒì„±"
        r'(\w+)\s*ì´ë¦„ìœ¼ë¡œ\s*í´ë”ë¥¼\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ ì´ë¦„ìœ¼ë¡œ í´ë”ë¥¼ ìƒì„±"
    ]
    
    # ê° íŒ¨í„´ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ìƒˆ í´ë” ì´ë¦„ ì¶”ì¶œ
    for pattern in patterns:
        match = re.search(pattern, command)
        if match:
            new_dir_name = match.group(1)
            break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì—ì„œ ì¤‘ë‹¨
    
    return new_dir_name


def get_parent_path(command, context):
    """
    ìƒˆ í´ë”ì˜ ë¶€ëª¨ ê²½ë¡œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        folder_name: ìƒì„±í•  í´ë” ì´ë¦„(A)
    
    Returns:
        str: ë¶€ëª¨ ê²½ë¡œ (ê¸°ì¡´ ê²½ë¡œ ë˜ëŠ” 'create_folder/B' í˜•íƒœ)
    """
    # 1. í˜„ì¬ ìœ„ì¹˜ ê´€ë ¨ íŒ¨í„´ í™•ì¸ (ìµœìš°ì„ )
    current_location_patterns = [
        r'í˜„ì¬\s*ë””ë ‰í† ë¦¬',      # "í˜„ì¬ ë””ë ‰í† ë¦¬ì—"
        r'í˜„ì¬\s*ìœ„ì¹˜',         # "í˜„ì¬ ìœ„ì¹˜ì—" 
        r'í˜„ì¬\s*í´ë”',         # "í˜„ì¬ í´ë”ì—"
        r'ì´\s*ìœ„ì¹˜',          # "ì´ ìœ„ì¹˜ì—"
        r'ì´\s*í´ë”',          # "ì´ í´ë”ì—"
        r'ì—¬ê¸°',              # "ì—¬ê¸°ì—"
        r'ì§€ê¸ˆ\s*ìœ„ì¹˜',         # "ì§€ê¸ˆ ìœ„ì¹˜ì—"
        r'ì´ê³³'               # "ì´ê³³ì—"
    ]
    
    for pattern in current_location_patterns:
        if re.search(pattern, command):
            return context.currentPath or '/'
    
    # 2. ì‚¬ìš©ì ëª…ë ¹ì—ì„œ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì´ë¦„(B) ì¶”ì¶œ
    parent_dir_name = None
    
    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ìœ„ì¹˜ ì¶”ì¶œ ì‹œë„
    patterns = [
        r'(\w+)\s*í´ë”\s*ì•ˆì—',  # "í”„ë¡œì íŠ¸ í´ë” ì•ˆì—"
        r'(\w+)\s*í´ë”\s*ë‚´ì—',  # "í”„ë¡œì íŠ¸ í´ë” ë‚´ì—" 
        r'(\w+)\s*ë””ë ‰í† ë¦¬\s*ì•ˆì—',  # "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì•ˆì—"
        r'(\w+)\s*ë””ë ‰í† ë¦¬\s*ë‚´ì—',  # "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë‚´ì—"
        r'(\w+)\s*ë‚´ì—\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ ë‚´ì— ìƒì„±" 
        r'(\w+)\s*ì•ˆì—\s*ìƒì„±',  # "í”„ë¡œì íŠ¸ ì•ˆì— ìƒì„±"
        r'(\w+)\s*í´ë”\s*ì•„ë˜',  # "í”„ë¡œì íŠ¸ í´ë” ì•„ë˜"
        r'(\w+)\s*ë””ë ‰í† ë¦¬\s*ì•„ë˜',  # "í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì•„ë˜"
    ]
    
    # ê° íŒ¨í„´ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„í•˜ì—¬ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì´ë¦„ ì¶”ì¶œ
    for pattern in patterns:
        match = re.search(pattern, command)
        if match:
            parent_dir_name = match.group(1)
            break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì—ì„œ ì¤‘ë‹¨
    
    # 3. availableFoldersì—ì„œ ë§¤ì¹­ë˜ëŠ” path ì°¾ê¸°
    if parent_dir_name:
        for folder in context.availableFolders:
            if folder.get('name') == parent_dir_name:
                return folder.get('path')  # C ê°’ ë°˜í™˜
        
        # ë§¤ì¹­ë˜ëŠ” í´ë”ê°€ ì—†ëŠ” ê²½ìš° 'create_folder/B' ë°˜í™˜
        return 'create_folder/' + parent_dir_name
    
    # ë¶€ëª¨ ë””ë ‰í† ë¦¬ê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš° í˜„ì¬ ê²½ë¡œ ì‚¬ìš©
    return context.currentPath or '/'

def generate_create_folder_description(folder_name, parent_path):
    """
    í´ë” ìƒì„± ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        folder_name: ìƒì„±í•  í´ë” ì´ë¦„
        parent_path: í´ë” ìƒì„± ìœ„ì¹˜
            
    Returns:
        str: í´ë” ìƒì„± ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥
    """
    # parent_pathì— 'create_folder' ë¬¸ìì—´ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if 'create_folder' in parent_path:
        # 'create_folder/'ë¥¼ ì œê±°í•œ ê°’ì„ parent_dir_nameì— í• ë‹¹
        parent_dir_name = parent_path.replace('create_folder/', '')
    else:
        # parent_pathë¥¼ '/'ë¡œ splití•˜ê³  ê°€ì¥ ë§ˆì§€ë§‰ ê²½ë¡œ ë¬¸ìì—´ì„ ê°€ì ¸ì˜´
        path_parts = parent_path.strip('/').split('/')
        # ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ ë£¨íŠ¸ ê²½ë¡œì¸ ê²½ìš° ì²˜ë¦¬
        if path_parts and path_parts[0]:
            parent_dir_name = path_parts[-1]
        else:
            parent_dir_name = 'ë£¨íŠ¸'
    
    # ê²°ê³¼ ë¬¸ìì—´ ìƒì„±
    result_desc = f"{parent_dir_name} ë‚´ì— {folder_name} í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    
    return result_desc


def get_search_term(command):
    """
    ì‚¬ìš©ìì˜ ëª…ë ¹ì—ì„œ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì¶”ì¶œí•œë‹¤.
    
    Args:
        command: ì‚¬ìš©ìì˜ ìì—°ì–´ ëª…ë ¹
        
    Returns:
        str: ì¶”ì¶œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ
    """
    # 1. íŒŒì¼ëª… ê²€ìƒ‰ íŒ¨í„´ (í™•ì¥ì í¬í•¨) - ì´ê²ƒì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    filename_pattern = r'([^\s]+\.\w+)'
    filename_match = re.search(filename_pattern, command)
    if filename_match:
        return filename_match.group(1)
    
    # 2. ê²€ìƒ‰ ëª…ë ¹ì–´ì™€ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
    search_term = clean_search_command(command)
    
    return search_term

def clean_search_command(command):
    """
    ê²€ìƒ‰ ëª…ë ¹ì—ì„œ ë¶ˆí•„ìš”í•œ ëª…ë ¹ì–´ ë¶€ë¶„ë§Œ ì œê±°í•˜ê³  
    ì¤‘ìš”í•œ ê²€ìƒ‰ í‚¤ì›Œë“œì™€ ì»¨í…ìŠ¤íŠ¸ëŠ” ìœ ì§€í•œë‹¤.
    
    Args:
        command: ì›ë³¸ ëª…ë ¹ì–´
        
    Returns:
        str: ì •ë¦¬ëœ ê²€ìƒ‰ì–´
    """
    # ì œê±°í•  ëª…ë ¹ì–´ íŒ¨í„´ë“¤ (ìˆœì„œ ì¤‘ìš”)
    remove_patterns = [
        # ë¬¸ì¥ ë íŒ¨í„´ë“¤ (ë¬¼ìŒí‘œ í¬í•¨)
        r'\s*ì°¾ì•„\s*ì¤˜?\s*\??$',
        r'\s*ê²€ìƒ‰\s*í•´?\s*ì¤˜?\s*\??$',
        r'\s*ì–´ë””\s*ìˆì–´\s*\??$',
        r'\s*ì–´ë””\s*ì—?\s*ìˆë‚˜\s*\??$',
        r'\s*ì–´ë””\s*ìˆì§€\s*\??$',
        r'\s*ì–´ë””\s*ì—?\s*ì €ì¥\s*ë˜ì–´?\s*ìˆì–´\s*\??$',
        r'\s*í™•ì¸\s*í•´?\s*ì¤˜?\s*\??$',
        r'\s*ì•Œë ¤\s*ì¤˜?\s*\??$',
        r'\s*ì°¾ì•„\s*ë´?\s*\??$',
        r'\s*ìœ„ì¹˜\s*ì•Œë ¤\s*ì¤˜?\s*\??$',
        r'\s*ê²½ë¡œ\s*ì•Œë ¤\s*ì¤˜?\s*\??$',
        r'\s*ì–´ë””\s*ì—?\s*$',
        r'\s*ì–´ë””\s*$',
        
        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤
        r'\s*ì´\s*ì–´ë””\s*ìˆì§€\s*\??$',  # 'íŒŒì¼ì´ ì–´ë””ìˆì§€?'
    ]
    
    # ì›ë³¸ ëª…ë ¹ì–´ ë³µì‚¬
    cleaned = command
    
    # íŒ¨í„´ ì œê±°
    for pattern in remove_patterns:
        cleaned = re.sub(pattern, '', cleaned)
    
    # ì¶”ê°€ ì •ë¦¬
    cleaned = cleaned.strip()
    
    # ë¹ˆ ë¬¸ìì—´ì´ë©´ ì›ë³¸ ë°˜í™˜
    if not cleaned:
        return command
    
    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬
    cleaned = handle_special_cases(cleaned, command)
    
    return cleaned


def handle_special_cases(cleaned, original):
    """
    íŠ¹ìˆ˜í•œ ì¼€ì´ìŠ¤ë“¤ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        cleaned: ì •ë¦¬ëœ ê²€ìƒ‰ì–´
        original: ì›ë³¸ ëª…ë ¹ì–´
        
    Returns:
        str: ìµœì¢… ê²€ìƒ‰ì–´
    """
    # '~ê°€ ì–´ë””ìˆëŠ”ì§€', '~ì´ ì–´ë””ìˆëŠ”ì§€' íŒ¨í„´ ì œê±°
    cleaned = re.sub(r'\s*ê°€\s*ì–´ë””\s*ìˆëŠ”ì§€\s*', '', cleaned)
    cleaned = re.sub(r'\s*ì´\s*ì–´ë””\s*ìˆëŠ”ì§€\s*', '', cleaned)
    
    # '~ì—ì„œ ~' íŒ¨í„´ ì²˜ë¦¬
    if 'ì—ì„œ' in cleaned:
        # 'ê³„ì•½ì„œì—ì„œ ì¡°ê±´ ê´€ë ¨ ë‚´ìš©' í˜•íƒœë¡œ ìœ ì§€
        parts = cleaned.split('ì—ì„œ', 1)
        if len(parts) == 2:
            doc = parts[0].strip()
            content = parts[1].strip()
            return f"{doc}ì—ì„œ {content}"
    
    # 'ë³´ê³ ì„œì— ë§¤ì¶œ ë°ì´í„°ê°€ ìˆëŠ”ì§€' â†’ 'ë³´ê³ ì„œ ë§¤ì¶œ ë°ì´í„°'
    if 'ì—' in cleaned and ('ë°ì´í„°ê°€' in cleaned or 'ìˆëŠ”ì§€' in cleaned):
        # 'ìˆëŠ”ì§€' ì œê±°
        cleaned = re.sub(r'\s*ìˆëŠ”ì§€\s*', '', cleaned)
        # 'ì—' â†’ ê³µë°±ìœ¼ë¡œ ë³€ê²½
        cleaned = re.sub(r'ì—\s+', ' ', cleaned)
        # 'ë°ì´í„°ê°€' â†’ 'ë°ì´í„°'
        cleaned = cleaned.replace('ë°ì´í„°ê°€', 'ë°ì´í„°')
    
    # '~ê°€ ìˆëŠ”ì§€' íŒ¨í„´ ì œê±°
    cleaned = re.sub(r'\s*ê°€\s*ìˆëŠ”ì§€\s*', '', cleaned)
    cleaned = re.sub(r'\s*ì´\s*ìˆëŠ”ì§€\s*', '', cleaned)
    
    # ë¶ˆí•„ìš”í•œ ì¡°ì‚¬ ì œê±° (ìˆœì„œ ì¤‘ìš”)
    # '~ë“¤' ì²˜ë¦¬ (íŒŒì¼ë“¤, ë¬¸ì„œë“¤)
    if 'ë“¤' in cleaned and ('íŒŒì¼ë“¤' in cleaned or 'ë¬¸ì„œë“¤' in cleaned):
        # 'íŒŒì¼ë“¤', 'ë¬¸ì„œë“¤'ì€ ìœ ì§€
        pass
    else:
        # ë‹¤ë¥¸ ê²½ìš°ì˜ 'ë“¤' ì œê±°
        cleaned = re.sub(r'(\w+)ë“¤\s+', r'\1 ', cleaned)
    
    # ê¸°íƒ€ ì¡°ì‚¬ ì •ë¦¬
    cleaned = re.sub(r'\s+ì„\s+', ' ', cleaned)
    cleaned = re.sub(r'\s+ë¥¼\s+', ' ', cleaned)
    cleaned = re.sub(r'\s+ì´\s+', ' ', cleaned)
    cleaned = re.sub(r'\s+ê°€\s+', ' ', cleaned)
    
    # ë¬¸ì¥ ë ì¡°ì‚¬ ì œê±°
    cleaned = re.sub(r'\s*ì„\s*$', '', cleaned)
    cleaned = re.sub(r'\s*ë¥¼\s*$', '', cleaned)
    cleaned = re.sub(r'\s*ì´\s*$', '', cleaned)
    cleaned = re.sub(r'\s*ê°€\s*$', '', cleaned)
    
    # ì¤‘ë³µ ê³µë°± ì œê±°
    cleaned = ' '.join(cleaned.split())
    
    return cleaned

def generate_search_description(search_term):
    description = f"'{search_term}'ì— ëŒ€í•œ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
    return description

def generate_summarize_description(context):
    """
    ìš”ì•½ ì‘ì—…ì— ëŒ€í•œ ì„¤ëª… ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        context: ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (selectedFiles í¬í•¨)
        
    Returns:
        str: "íŒŒì¼ëª…ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤." ë˜ëŠ” "ì„ íƒí•œ Xê°œ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤." í˜•íƒœì˜ ì„¤ëª… ë¬¸ì¥
    """
    # 1. selectedFilesì—ì„œ íŒŒì¼ ì´ë¦„ë“¤ ì¶”ì¶œ
    if not context.selectedFiles or len(context.selectedFiles) == 0:
        return "ì„ íƒëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
    
    file_count = len(context.selectedFiles)
    
    # 2. ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš°
    if file_count == 1:
        file_name = context.selectedFiles[0].get('name', 'ë¬¸ì„œ')
        # íŒŒì¼ í™•ì¥ì ì œê±°í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±
        clean_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
        result_desc = f"{clean_name}ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."
    
    # 3. ë³µìˆ˜ íŒŒì¼ì¸ ê²½ìš°
    else:
        # íŒŒì¼ ê°œìˆ˜ê°€ 3ê°œ ì´í•˜ì¸ ê²½ìš° ëª¨ë“  íŒŒì¼ëª… ë‚˜ì—´
        if file_count <= 3:
            file_names = []
            for file in context.selectedFiles:
                file_name = file.get('name', '')
                # íŒŒì¼ í™•ì¥ì ì œê±°
                clean_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
                file_names.append(clean_name)
            
            names_str = ', '.join(file_names)
            result_desc = f"{names_str}ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."
        
        # íŒŒì¼ ê°œìˆ˜ê°€ ë§ì€ ê²½ìš° ê°œìˆ˜ë¡œ í‘œì‹œ
        else:
            result_desc = f"ì„ íƒí•œ {file_count}ê°œ ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."

    return result_desc


# ===== ì‘ì—… ì‹¤í–‰ ë¡œì§ í—¬í¼ í•¨ìˆ˜ë“¤ =====

async def execute_operation_logic(operation_type: str, operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """
    ì‘ì—… íƒ€ì…ë³„ ì‹¤ì œ ì‹¤í–‰ ë¡œì§
    
    Args:
        operation_type: ì‘ì—… íƒ€ì…
        operation: ì‘ì—… ìƒì„¸ ì •ë³´
        user_options: ì‚¬ìš©ì ì˜µì…˜
        current_user: í˜„ì¬ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
    Returns:
        dict: ì‹¤í–‰ ê²°ê³¼ ì •ë³´
    """
    logger.info(f"Executing operation logic for type: {operation_type}")
    
    try:
        if operation_type == "move":
            return await execute_move_logic(operation, user_options, current_user, db)
        elif operation_type == "copy":
            return await execute_copy_logic(operation, user_options, current_user, db)
        elif operation_type == "delete":
            return await execute_delete_logic(operation, user_options, current_user, db)
        elif operation_type == "rename":
            return await execute_rename_logic(operation, user_options, current_user, db)
        elif operation_type == "create_folder":
            return await execute_create_folder_logic(operation, user_options, current_user, db)
        elif operation_type == "search":
            return await execute_search_logic(operation, user_options, current_user, db)
        elif operation_type == "summarize":
            return await execute_summarize_logic(operation, user_options, current_user, db)
        else:
            logger.error(f"Unknown operation type: {operation_type}")
            return {
                "message": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì‘ì—… íƒ€ì…ì…ë‹ˆë‹¤: {operation_type}",
                "undoAvailable": False
            }
            
    except Exception as e:
        logger.error(f"Error executing {operation_type} operation: {e}")
        return {
            "message": f"ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_move_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """ì´ë™ ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    
    targets = operation.get("targets", [])
    destination = operation.get("destination", "/")
    
    logger.info(f"Moving {len(targets)} files to {destination}")
    
    try:
        # process_directory_operations í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
        operations = []
        for target in targets:
            operations.append({
                "operation_type": "move",
                "item_id": target.get("id"),
                "name": target.get("name"),
                "target_path": destination,
                "path": destination  # target_pathì™€ path ë‘˜ ë‹¤ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë¥¼ ìœ„í•´
            })
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        success_count = sum(1 for r in results if r.get("status") == "success")
        failed_count = len(results) - success_count
        
        if failed_count > 0:
            message = f"{success_count}ê°œ íŒŒì¼ì´ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤. {failed_count}ê°œ ì‹¤íŒ¨"
        else:
            message = f"{len(targets)}ê°œ íŒŒì¼ì´ {destination}ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤"
        
        # ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        operation_results = [
            op_schemas.OperationResult(
                status=r.get("status", "unknown"),
                message=r.get("message", ""),
                item_id=r.get("item_id")
            ) for r in results
        ]
        
        return {
            "message": message,
            "undoAvailable": True,
            "undoDeadline": (datetime.now() + timedelta(minutes=10)).isoformat(),
            "results": operation_results
        }
        
    except Exception as e:
        logger.error(f"Error executing move operation: {e}")
        return {
            "message": f"íŒŒì¼ ì´ë™ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_copy_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """ë³µì‚¬ ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    
    targets = operation.get("targets", [])
    destination = operation.get("destination", "/")
    
    logger.info(f"Copying {len(targets)} files to {destination}")
    
    try:
        # process_directory_operations í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
        operations = []
        for target in targets:
            operations.append({
                "operation_type": "copy",
                "item_id": target.get("id"),
                "name": target.get("name"),
                "target_path": destination,
                "path": destination
            })
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        success_count = sum(1 for r in results if r.get("status") == "success")
        failed_count = len(results) - success_count
        
        if failed_count > 0:
            message = f"{success_count}ê°œ íŒŒì¼ì´ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤. {failed_count}ê°œ ì‹¤íŒ¨"
        else:
            message = f"{len(targets)}ê°œ íŒŒì¼ì´ {destination}ë¡œ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        
        # ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        operation_results = [
            op_schemas.OperationResult(
                status=r.get("status", "unknown"),
                message=r.get("message", ""),
                item_id=r.get("item_id")
            ) for r in results
        ]
        
        return {
            "message": message,
            "undoAvailable": False,  # ë³µì‚¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ undo ë¶ˆê°€
            "results": operation_results
        }
        
    except Exception as e:
        logger.error(f"Error executing copy operation: {e}")
        return {
            "message": f"íŒŒì¼ ë³µì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_delete_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """ì‚­ì œ ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    
    targets = operation.get("targets", [])
    
    logger.info(f"Deleting {len(targets)} files")
    
    try:
        # process_directory_operations í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
        operations = []
        for target in targets:
            operations.append({
                "operation_type": "delete",
                "item_id": target.get("id"),
                "name": target.get("name")
            })
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        success_count = sum(1 for r in results if r.get("status") == "success")
        failed_count = len(results) - success_count
        
        if failed_count > 0:
            message = f"{success_count}ê°œ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. {failed_count}ê°œ ì‹¤íŒ¨"
        else:
            message = f"{len(targets)}ê°œ íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
        
        # ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        operation_results = [
            op_schemas.OperationResult(
                status=r.get("status", "unknown"),
                message=r.get("message", ""),
                item_id=r.get("item_id")
            ) for r in results
        ]
        
        return {
            "message": message,
            "undoAvailable": False,  # ì‚­ì œëŠ” ì¼ë°˜ì ìœ¼ë¡œ undo ë¶ˆê°€ (ë³µêµ¬ ì–´ë ¤ì›€)
            "results": operation_results
        }
        
    except Exception as e:
        logger.error(f"Error executing delete operation: {e}")
        return {
            "message": f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_rename_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """ì´ë¦„ ë³€ê²½ ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    
    # renameì€ targetì´ ë°°ì—´ì´ ì•„ë‹Œ ë‹¨ì¼ ê°ì²´ ë˜ëŠ” ë°°ì—´ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ
    target = operation.get("target", {})
    if isinstance(target, list) and len(target) > 0:
        target = target[0]
    
    new_name = operation.get("newName", "")
    
    logger.info(f"Renaming file to {new_name}")
    
    try:
        # process_directory_operations í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
        operations = [{
            "operation_type": "rename",
            "item_id": target.get("id"),
            "name": new_name  # ìƒˆë¡œìš´ ì´ë¦„
        }]
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        if results and results[0].get("status") == "success":
            message = f"íŒŒì¼ ì´ë¦„ì´ '{new_name}'ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤"
        else:
            message = "íŒŒì¼ ì´ë¦„ ë³€ê²½ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
        
        # ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        operation_results = [
            op_schemas.OperationResult(
                status=r.get("status", "unknown"),
                message=r.get("message", ""),
                item_id=r.get("item_id")
            ) for r in results
        ]
        
        return {
            "message": message,
            "undoAvailable": True,
            "undoDeadline": (datetime.now() + timedelta(minutes=10)).isoformat(),
            "results": operation_results
        }
        
    except Exception as e:
        logger.error(f"Error executing rename operation: {e}")
        return {
            "message": f"íŒŒì¼ ì´ë¦„ ë³€ê²½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_create_folder_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """í´ë” ìƒì„± ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    
    folder_name = operation.get("folderName", "")
    parent_path = operation.get("parentPath", "/")
    
    logger.info(f"Creating folder '{folder_name}' in {parent_path}")
    
    try:
        # process_directory_operations í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ì¤€ë¹„
        operations = [{
            "operation_type": "create",
            "name": folder_name,
            "path": parent_path,
            "target_path": parent_path  # create ì‘ì—…ì€ path ë˜ëŠ” target_path ì‚¬ìš©
        }]
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        if results and results[0].get("status") == "success":
            message = f"'{folder_name}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
        else:
            message = "í´ë” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
        
        # ê²°ê³¼ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        operation_results = [
            op_schemas.OperationResult(
                status=r.get("status", "unknown"),
                message=r.get("message", ""),
                item_id=r.get("item_id")
            ) for r in results
        ]
        
        return {
            "message": message,
            "undoAvailable": True,
            "undoDeadline": (datetime.now() + timedelta(minutes=10)).isoformat(),
            "results": operation_results
        }
        
    except Exception as e:
        logger.error(f"Error executing create folder operation: {e}")
        return {
            "message": f"í´ë” ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_search_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """ê²€ìƒ‰ ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from rag.document_service import process_query
    from rag.llm import get_llms_answer
    from db.database import engine
    
    search_term = operation.get("searchTerm", "")
    
    logger.info(f"Searching for: {search_term}")
    
    try:
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        # process_queryëŠ” ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ë“¤ì„ ë°˜í™˜
        docs = process_query(current_user.id, search_term, engine)
        
        # LLMì„ í†µí•´ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±
        answer = get_llms_answer(docs, search_term)
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
        found_documents = []
        for doc in docs:
            if hasattr(doc, 'metadata') and doc.metadata:
                found_documents.append({
                    "name": doc.metadata.get('document_name', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                    "path": doc.metadata.get('document_path', '/')
                })
        
        # ì¤‘ë³µ ì œê±°
        unique_documents = []
        seen = set()
        for doc in found_documents:
            doc_key = (doc['name'], doc['path'])
            if doc_key not in seen:
                seen.add(doc_key)
                unique_documents.append(doc)
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        search_documents = [
            op_schemas.SearchDocument(
                name=doc["name"],
                path=doc["path"]
            ) for doc in unique_documents
        ]
        
        search_result_data = op_schemas.SearchResultData(
            answer=answer,
            documents=search_documents,
            documentCount=len(unique_documents)
        )
        
        return {
            "message": f"'{search_term}' ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "undoAvailable": False,  # ê²€ìƒ‰ì€ undo ë¶ˆí•„ìš”
            "searchResults": search_result_data
        }
        
    except Exception as e:
        logger.error(f"Error executing search operation: {e}")
        return {
            "message": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


async def execute_summarize_logic(operation: dict, user_options: dict, current_user: User, db: Session) -> dict:
    """ìš”ì•½ ì‘ì—… ì‹¤í–‰ ë¡œì§"""
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import PromptTemplate
    from db import crud
    import boto3
    from config.settings import S3_BUCKET_NAME, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION
    
    targets = operation.get("targets", [])
    
    logger.info(f"Summarizing {len(targets)} documents")
    
    try:
        # S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        s3_client = boto3.client(
            's3',
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_DEFAULT_REGION
        )
        
        # ê° ë¬¸ì„œì˜ ë‚´ìš©ì„ ê°€ì ¸ì™€ì„œ ìš”ì•½
        summaries = []
        
        for target in targets:
            target_id = target.get("id")
            target_name = target.get("name", "ë¬¸ì„œ")
            
            # íŒŒì¼ì¸ ê²½ìš°ì—ë§Œ ì²˜ë¦¬ (í´ë”ëŠ” ê±´ë„ˆë›°ê¸°)
            if target.get("type") == "folder":
                continue
            
            # S3 í‚¤ ê°€ì ¸ì˜¤ê¸°
            s3_key = crud.get_s3_key_by_id(db, target_id)
            
            if not s3_key:
                logger.warning(f"S3 key not found for document {target_id}")
                continue
            
            # S3ì—ì„œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            try:
                response = s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=s3_key)
                file_content = response['Body'].read()
                
                # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                file_extension = target_name.split('.')[-1].lower()
                
                if file_extension == 'pdf':
                    from rag.file_load import load_pdf
                    documents = await load_pdf(file_content)
                elif file_extension == 'docx':
                    from rag.file_load import load_docx
                    documents = await load_docx(file_content)
                elif file_extension in ['hwp', 'hwpx']:
                    from rag.file_load import load_hwp
                    documents = await load_hwp(file_content, file_extension)
                else:
                    logger.warning(f"Unsupported file type: {file_extension}")
                    continue
                
                # ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°
                full_text = "\n".join(documents)
                
                # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
                if len(full_text) > 10000:
                    full_text = full_text[:10000] + "..."
                
                # LLMìœ¼ë¡œ ìš”ì•½
                llm = ChatOpenAI(
                    temperature=0.3,
                    max_tokens=500,
                    model_name="gpt-4o-mini"
                )
                
                prompt = PromptTemplate.from_template(
                    """ë‹¤ìŒ ë¬¸ì„œì˜ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. í•µì‹¬ ë‚´ìš©ì„ ì¤‘ì‹¬ìœ¼ë¡œ 3-5ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.
                    
                    ë¬¸ì„œëª…: {document_name}
                    
                    ë‚´ìš©:
                    {content}
                    
                    ìš”ì•½:"""
                )
                
                chain = prompt | llm
                summary = chain.invoke({
                    "document_name": target_name,
                    "content": full_text
                })
                
                summaries.append({
                    "name": target_name,
                    "summary": summary.content if hasattr(summary, 'content') else str(summary)
                })
                
            except Exception as e:
                logger.error(f"Error summarizing document {target_name}: {e}")
                summaries.append({
                    "name": target_name,
                    "summary": f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                })
        
        # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
        if len(summaries) == 0:
            message = "ìš”ì•½í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤"
        else:
            message = f"{len(summaries)}ê°œ ë¬¸ì„œì˜ ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
        
        # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        summary_data_list = [
            op_schemas.SummaryData(
                name=summary["name"],
                summary=summary["summary"]
            ) for summary in summaries
        ]
        
        return {
            "message": message,
            "undoAvailable": False,  # ìš”ì•½ì€ undo ë¶ˆí•„ìš”
            "summaries": summary_data_list
        }
        
    except Exception as e:
        logger.error(f"Error executing summarize operation: {e}")
        return {
            "message": f"ë¬¸ì„œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "undoAvailable": False
        }


# ===== Undo ë¡œì§ í—¬í¼ í•¨ìˆ˜ë“¤ =====

async def execute_undo_logic(operation_type: str, undo_data: dict, reason: str, current_user: User, db: Session) -> dict:
    """
    ì‘ì—… íƒ€ì…ë³„ undo ë¡œì§
    
    Args:
        operation_type: ì›ë³¸ ì‘ì—… íƒ€ì…
        undo_data: undoë¥¼ ìœ„í•œ ë°ì´í„°
        reason: undo ì‚¬ìœ 
        current_user: í˜„ì¬ ì‚¬ìš©ì
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
    Returns:
        dict: undo ê²°ê³¼ ì •ë³´
    """
    # operation_typeì´ ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•Šì€ ê²½ìš° undo_dataì—ì„œ ì¶”ì¶œ
    if not operation_type and undo_data:
        operation = undo_data.get("operation", {})
        operation_type = operation.get("type")
    
    logger.info(f"Executing undo logic for type: {operation_type}, reason: {reason}")
    
    try:
        if operation_type == "move":
            return await undo_move_logic(undo_data, reason, current_user, db)
        elif operation_type == "rename":
            return await undo_rename_logic(undo_data, reason, current_user, db)
        elif operation_type == "create_folder":
            return await undo_create_folder_logic(undo_data, reason, current_user, db)
        else:
            return op_schemas.UndoResult(
                success=False,
                error=f"'{operation_type}' ì‘ì—…ì€ ë˜ëŒë¦¬ê¸°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
            ).dict()
            
    except Exception as e:
        logger.error(f"Error undoing {operation_type} operation: {e}")
        return op_schemas.UndoResult(
            success=False,
            error=f"ë˜ëŒë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ).dict()


async def undo_move_logic(undo_data: dict, reason: str, current_user: User, db: Session) -> dict:
    """ì´ë™ ì‘ì—… ë˜ëŒë¦¬ê¸° ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    from db import crud
    
    # undo_dataì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    operation = undo_data.get("operation", {})
    targets = operation.get("targets", [])
    original_destination = operation.get("destination", "/")
    
    logger.info(f"Undoing move operation: moving {len(targets)} files back from {original_destination}")
    
    try:
        # ê° íŒŒì¼ì˜ ì›ë˜ ìœ„ì¹˜ ì°¾ê¸°
        operations = []
        for target in targets:
            target_id = target.get("id")
            target_name = target.get("name")
            original_path = target.get("path", "/")
            
            # ì›ë˜ ê²½ë¡œì—ì„œ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì¶”ì¶œ
            if original_path == "/" or original_path == f"/{target_name}":
                original_parent_path = "/"
            else:
                # íŒŒì¼ëª…ì„ ì œê±°í•˜ì—¬ ë¶€ëª¨ ê²½ë¡œ ì–»ê¸°
                path_parts = original_path.rstrip('/').split('/')
                if path_parts[-1] == target_name:
                    path_parts = path_parts[:-1]
                original_parent_path = '/'.join(path_parts) if path_parts else '/'
            
            operations.append({
                "operation_type": "move",
                "item_id": target_id,
                "name": target_name,
                "target_path": original_parent_path,
                "path": original_parent_path
            })
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        success_count = sum(1 for r in results if r.get("status") == "success")
        
        if success_count == len(targets):
            return op_schemas.UndoResult(
                success=True,
                message=f"{len(targets)}ê°œ íŒŒì¼ì´ ì›ë˜ ìœ„ì¹˜ë¡œ ë˜ëŒë ¤ì¡ŒìŠµë‹ˆë‹¤"
            ).dict()
        else:
            return op_schemas.UndoResult(
                success=False,
                error=f"ì¼ë¶€ íŒŒì¼ì„ ë˜ëŒë¦¬ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (ì„±ê³µ: {success_count}/{len(targets)})"
            ).dict()
            
    except Exception as e:
        logger.error(f"Error undoing move operation: {e}")
        return op_schemas.UndoResult(
            success=False,
            error=f"ì´ë™ ì‘ì—… ë˜ëŒë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ).dict()


async def undo_rename_logic(undo_data: dict, reason: str, current_user: User, db: Session) -> dict:
    """ì´ë¦„ ë³€ê²½ ì‘ì—… ë˜ëŒë¦¬ê¸° ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    from db import crud
    
    # undo_dataì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    operation = undo_data.get("operation", {})
    target = operation.get("target", {})
    if isinstance(target, list) and len(target) > 0:
        target = target[0]
    
    new_name = operation.get("newName", "")
    target_id = target.get("id")
    original_name = target.get("name", "")
    
    logger.info(f"Undoing rename operation: changing '{new_name}' back to '{original_name}'")
    
    try:
        # ì´ë¦„ì„ ì›ë˜ëŒ€ë¡œ ë˜ëŒë¦¬ê¸°
        operations = [{
            "operation_type": "rename",
            "item_id": target_id,
            "name": original_name  # ì›ë˜ ì´ë¦„ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
        }]
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        if results and results[0].get("status") == "success":
            return op_schemas.UndoResult(
                success=True,
                message=f"íŒŒì¼ ì´ë¦„ì´ '{original_name}'ìœ¼ë¡œ ë˜ëŒë ¤ì¡ŒìŠµë‹ˆë‹¤"
            ).dict()
        else:
            return op_schemas.UndoResult(
                success=False,
                error="íŒŒì¼ ì´ë¦„ì„ ë˜ëŒë¦¬ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
            ).dict()
            
    except Exception as e:
        logger.error(f"Error undoing rename operation: {e}")
        return op_schemas.UndoResult(
            success=False,
            error=f"ì´ë¦„ ë³€ê²½ ì‘ì—… ë˜ëŒë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ).dict()


async def undo_create_folder_logic(undo_data: dict, reason: str, current_user: User, db: Session) -> dict:
    """í´ë” ìƒì„± ì‘ì—… ë˜ëŒë¦¬ê¸° ë¡œì§"""
    from fast_api.endpoints.documents import process_directory_operations
    from db import crud
    
    # undo_dataì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    operation = undo_data.get("operation", {})
    folder_name = operation.get("folderName", "")
    parent_path = operation.get("parentPath", "/")
    
    # ìƒì„±ëœ í´ë”ì˜ ì „ì²´ ê²½ë¡œ ê³„ì‚°
    if parent_path == "/":
        folder_path = f"/{folder_name}"
    else:
        folder_path = f"{parent_path}/{folder_name}"
    
    logger.info(f"Undoing create folder operation: deleting folder '{folder_name}' at {folder_path}")
    
    try:
        # í´ë”ì˜ ID ì°¾ê¸°
        folder_id = crud.get_directory_id_by_path(db, folder_path)
        
        if not folder_id:
            return op_schemas.UndoResult(
                success=False,
                error=f"ì‚­ì œí•  í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {folder_path}"
            ).dict()
        
        # í´ë” ì‚­ì œ
        operations = [{
            "operation_type": "delete",
            "item_id": folder_id,
            "name": folder_name
        }]
        
        # ì‘ì—… ì‹¤í–‰
        results = await process_directory_operations(operations, current_user.id, db)
        
        # ê²°ê³¼ í™•ì¸
        if results and results[0].get("status") == "success":
            return op_schemas.UndoResult(
                success=True,
                message=f"ìƒì„±ëœ í´ë” '{folder_name}'ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"
            ).dict()
        else:
            return op_schemas.UndoResult(
                success=False,
                error="í´ë”ë¥¼ ì‚­ì œí•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
            ).dict()
            
    except Exception as e:
        logger.error(f"Error undoing create folder operation: {e}")
        return op_schemas.UndoResult(
            success=False,
            error=f"í´ë” ìƒì„± ì‘ì—… ë˜ëŒë¦¬ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ).dict()
